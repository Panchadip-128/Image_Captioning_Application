Sentiment Analysis Chatbot with Image Captioning
Overview:
----------
This project combines sentiment analysis with image captioning using the Salesforce BLIP model and Hugging Face's Transformers library. The chatbot analyzes text input sentiment and provides captions for uploaded images.

![conditional image captioning](https://github.com/Panchadip-128/Image_Captioning_Application/assets/165953910/43c6cea1-9dd9-46ea-9033-256ce9938910)


Tools Used:
------------
Python: Backend development and machine learning.
Flask: Web framework for handling backend requests.
Streamlit: Tool for deploying and serving the web application.
Hugging Face Transformers: Library for NLP and image captioning.
HTML, CSS, JavaScript: Frontend development for user interaction.

Setup:
------

Install Dependencies:
pip install transformers torch torchvision flask streamlit pillow

Run the Application:
---------------------

Backend:

python app.py
Frontend (Streamlit):

streamlit run frontend.py
Accessing the Application:

Open your browser and navigate to http://localhost:8501 to interact with the chatbot and image captioning interface.

File Structure:
----------------
app.py: Flask backend for processing requests.
frontend.py: Streamlit frontend for user interface.
requirements.txt: List of Python dependencies.


Usage:
------
Sentiment Analysis:

Enter text in the chat interface and receive sentiment analysis results.

Image Captioning:
--------------

Upload an image to get automated captions generated by the BLIP model.
![conditional img captioning result](https://github.com/Panchadip-128/Image_Captioning_Application/assets/165953910/9c0de0d7-94a2-4583-b47b-f30fdba07daf)
![various options available](https://github.com/Panchadip-128/Image_Captioning_Application/assets/165953910/e7d5cd07-00a7-4076-8298-f844bc030ef9)


Deployment:
------------
Deployed using GRADIO for easy web deployment and sharing.
